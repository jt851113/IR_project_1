The storage layer at the peer P(Q) responsible for the
query Q is in charge of (1) the management of the relevance
feedback information received by P(Q) for Q, and (2) for the
generation of the results to be sent back to a user submitting
the query Q to the system.
Concepts. The main problem for the design of an efficient
storage layer is the potential heavy skewness of the relevance
feedback generation process (see also 3.2).
Under such conditions, it is therefore unrealistic to keep all
the available relevance feedback information (as peers with
highly used queries would quickly run out of main memory
storage). Some sort of storage control mechanism must
be implemented. Relying for this on some document-query
relevance measure for evaluating the quality of relevance
feedback items containing the considered document-query
pair is potentially problematic. Indeed, (1) the most efficient
document relevance scoring techniques (e.g. the linkbased
PageRank used by Google) are notably costly in a
distributed set up; and (2) document relevance seems, by nature,
not well adapted to the type of information processed
by our system. Because they are all directly generated by
users and all represent some form of user interest, the processed
relevance feedback items should rather be considered
of quite comparable intrinsic quality. Thus, discriminating
between them needs to rely on other criteria, in our case,
popularity and semantic coverage.
Popularity. A relevance feedback information associating
a document D to a query Q is popular, if it is frequently
produced by many users, and thus results in a high arrival
rate at the peer responsible for Q. More precisely, the popularity
of a relevance feedback item relating D to Q is the
rate p(D) of the stochastic process modeling the arrival at
P(Q) of relevance feedback information for D. An important
part of the storage management mechanism described
hereafter is therefore dedicated to make the selection of the
stored items adaptively sensitive to the p(D) rates.
Semantic coverage. Another important aspect to consider
when selecting interesting relevance feedback information
is the amount of semantic content the associated document
brings w.r.t. the other documents already present
in the system through other relevance feedback items. The
goal is then to maintain a set of relevance feedback items
providing a satisfactory coverage of the topics expressed in
the documents present in the relevance feedback items associated
with a given query. More precisely, in line with
what was already mentioned in section 2.3.1 about User interest
profiling, we measure the “semantic redundancy” of
a relevance feedback item by the maximal similarity of the
associated document profile with the document profiles of
the documents already stored in the system. A second important
part of our storage management mechanism design
is therefore dedicated to make the relevance feedback item
selection sensitive to document profile similarities. In this
perspective, the goal is to focus on relevance feedback items
with maximal relative similarities that are minimal, so as to
maintain a maximal semantic coverage in the set of stored
relevance feedback items.
Finally, in order to achieve a globally satisfactory storage
management mechanism, it is also crucial to provide
some ways to arbitrate between the two considered criteria
(popularity and coverage). In our approach, we rely on the
assumption that semantic coverage is less crucial for currently
popular relevance feedback items, but very important
for items that used to be popular in the past but progressively
came out of trend. The underlying idea is that, for
current “hot topics” (i.e., topics expressed in documents as-
sociated with currently popular relevance feedback items),
the users are expecting a much higher level of detail than for
topics that used to be popular in the past, for which only
the main involved issues might be considered. In a nutshell,
for selecting relevance feedback items corresponding to current
hot topics, popularity is crucial, while for selecting the
items that keep track of past hot topics, semantic coverage
is more adequate. In consequence, our storage management
mechanism aims at selecting the currently most popular relevance
feedback items without taking semantic coverage into
account, but in parallel, aims at preserving the relevance
feedback items that used to be popular in the past without
taking into account their current popularity.
Implementation. This section describes the targeted implementation
of our relevance feedback information management
mechanism. For readability purposes, the expression
“relevance feedback”is often abbreviated to RF, for example,
relevance feedback items are often simply called RFitems.
As already mentioned earlier in the section 2.3.2, the RF
information concerning a query Q received from the network
by the peer responsible for Q consists of a triple (Q,D,DP),
where D is the information available about the considered
document (mainly the document URL uniquely identifying
the document, and a document summary containing the title
and the snippet as it is quite standard in Web search
engines), and DP is the Bloom filter representing the document
profile. When acquired from the network, an RF
information is first transformed into an internal data structure,
an RFitem, which stores the (Q,D,DP) triple (plus
other attributes required for the processing, such as its occurrence
frequency or its maximal semantic similarity) in an
easily computable way.
The general goal of the RF information management mechanism
is then to process all the triples received by P(Q) in
order to select the ones that should be stored at P(Q) for
retrieval purposes. From a more computational perspective,
the essential aspect is that the storage management
mechanism requires a strictly bounded storage space that
is controlled by a “maximal storage space” parameter (denoted
by S in the rest of this section). There is no reason
why this parameter should be the same on all the peers. On
the contrary, it is probably advisable to adapt it when possible,
for example to the observed average RF information
arrival rate at the peer. Having a strictly bounded storage
consumption is clearly a necessary feature to realistically
consider a deployment of the CFRS system on a true set of
peers, but it also strongly impacts how the peer performs
its RF information management: the bigger the value for
S, the higher the quality of the storage management. More
precisely, with a larger storage space, the peer will be able
to store more popular RFitems, and to keep a larger set of
past popular RFitems, thus improving its overall semantic
coverage. The adaptability of the algorithm makes it able
to cope with large ranges of possible storage space: for what
ever provided value for S, it will try to perform in a way that
fits best the true distribution of the RF information receive
by the peer.
The fixed size storage space is split into two distinct parts:
the main store, and the archive. The purpose of the main
store is to progressively identify and store the popular RFitems
received by the peer, while the archive serves to identify
and store the past popular RFitems providing an acceptable
semantic coverage. Figure 3 shows the main components of
the storage layer and how they process the RFitems.
The main store. The main store is decomposed into a
variable size FIFO (First In, First Out) queue and a variable
size associative memory (hereafter called the popularunpopular
store, and abbreviated to “the POPstore”).
The queue is a temporal storage that serves as an “incubator”
for the identification of popular RFitems. It contains
the sequence of references to all the RFitems received by the
peer during the time interval covered by the queue. RFitems
themselves are stored in the POPstore, which is a map
between URLs and RFItems. Both the queue and the POPstore
are of variable size, which means that they grow or
shrink independently (within the S bound imposed to the
whole storage space) depending on the storage requirements
imposed by the occurrence distribution of the received RFitems.
Each time a new RFitem r is acquired from the network,
the POPstore is queried to check whether r is already
present. In this case, its occurrence frequency is incremented
and a reference to r is pushed into the queue. Otherwise, r
is inserted into the POPstore with an occurrence frequency
set to 1. If not enough storage space is available (either for
the push or for the insertion), the oldest RFitem reference
is poped from the queue, and the occurrence frequency of
the corresponding oldestRFitem in the POPstore is decremented.
If the updated occurrence frequency of the poped oldest-
RFitem roldest reaches zero (i.e., there is no more reference
to it in the queue), roldest is removed from POPstore. In
addition, if its maximal frequency (i.e., the maximal occurrence
frequency observed for roldest during its lifetime in
POPstore) is greater than a predefined popularity threshold
Freqmin, roldest is inserted in the archive with the current
value of its maximal frequency. Otherwise, roldest is simply
abandoned.
If the processing of the poped oldestRFitem roldest did not
free any storage space (i.e., its frequency it still non zero),
the whole pop cycle is reiterated for the new currently oldest
RFItem, until an RFitem with a frequency of zero is removed
from the POPstore. The new acquired RFitem is eventually
inserted in the POPstore and a its reference is pushed in the
queue.
The archive. The archive is another variable size associative
memory (indexed by the RFitem URLs) used to
store past popular RFitems that have been rejected from the
POPstore because their occurrence frequency in the queue
has dropped to zero, but that were once popular (i.e., heir
maximal occurrence frequency maxFreq is above the Freqmin
popularity threshold) is above the Freqmin popularity
threshold). The purpose of this additional store is twofold.
First, it is used to cope with the “burst” phenomena (i.e.,
a topic becoming suddenly extremely popular) that are frequently
observed (e.g. on the Web), and can lead to the
“flooding” of popularity based storage mechanisms with a
limited number of very popular topics that expel all the
other topics from the system. To some extent, the archive
serves as a long term memory, while the queue-POPstore
pair operates with a much shorter horizon (limited by the
current time span covered by the queue). Second, the archive
is the data structure that implements the semantic coverage
based filtering mechanism.
As already mentioned, the semantic coverage based filtering
mechanism relies on the notion of maximal document
similarity that is derived from the document profiles associated
with the stored RFitems. For this purpose, (1) each
of the RFitems present in the archive is associated with a
semantic redundancy score corresponding to the maximal
similarity between its document profile and the documents
profiles of all the popular RFitems in POPstore and all the
RFitems in the archive; (2) the archive provides the possibility
to efficiently access the most recent of the RFitems
with the highest semantic redundancy it contains (hereafter
called the closest RFitem and denoted by closestRFitem);
and (3) each time a past popular RFitem needs to be inserted,
if not enough storage is available for this operation,
the current closestRFitem is first removed from the archive
(and abandoned), and then the new past popular item is
inserted.
As the computation of the required RTitem scores is a
relatively costly procedure, it is not performed each time a
change impacting the scores happens, but only when the ratio
between the number of changes (insertions or removals)
that happened in the POPstore and the archive since last
score update w.r.t. the POPstore+archive size exceeds a
predefined threshold , which thus allows to control the
tradeoff between score accuracy and computational cost.
Finally, as the archive is an adaptive variable size data
structure, it is important to provide some control on the
storage space it consumes (w.r.t. the one used by the POPstore
that competes for the same storage resource). For this
purpose, our design provides a parameter  that imposes
that at least a fraction  of the size of the POPstore is reserved
for the archive.
Answering queries. When the peer P(Q) receives the
request (under the format (Q,UP)), the storage layer extracts
from the popular RFitem in the POPstore and the
past popular RFitem in the archive the list of of the k-most
similar RFitem w.r.t the user profiles UP, and sends back
the resulting list of documents descriptors (URL, title, snippet).