A dataset exhibiting fractal behavior is self-similar over a large range of
scales. In other words, a fractal dataset exhibits roughly the same properties
for a wide variation in scale or size, such that parts of any size of the data are
similar (exactly or statistically) to the whole dataset.) The idea of self-similarity
is illustrated in Fig. 4. The Sierpinsky triangle is a well-known geometric fractal
object generated through iterations of a recursive process, as follows. Let ABC
be an equilateral triangle, from which the middle triangle A'B'C' is removed
The three remaining triangles also have their middles removed, and the same
procedure is repeated recursively. Note that each smaller triangle in each level
is exactly similar to the whole Sierpinsky triangle.
In mathematical theory, due to an infinite construction process, the
perimeter of the Sierpinsky triangle tends to infinite and its area tends to zero.
Thus, although its embedding dimension equals two, the Sierpinsky triangle is
neither a one-dimensional nor a two-dimensional object. In fact, its intrinsic
dimension (or fractal dimension) equals log(3)= log(2) = 1:58. (An analytical
method to find the fractal dimension of fractals generated by iterative processes
can be found, for example, in Reference).)
The fractal behavior of self-similar real datasets leads to a distribution
of distances that follows a power law.) It has been shown) that, given a
dataset S of N elements and a distance function d(si; sj), the average
number k of neighbors within a distance r is proportional to r raised to D. Thus,
the number of pairs of elements within distance r (the pair-count PC(r)), follows
a power law, where Kp is a proportionality constant:
Observe that by evaluating the distances between every two elements of
a dataset S we can plot a graph of PC(r) versus r to depict the distribution of
distances in S. For a self-similar (fractal) dataset, the distribution of distances
plotted in log-log scale is straight for a significant range of r, such that the slope
of the best-fitting line corresponds to the exponent in Equation 1 and closely
approaches the intrinsic dimension D of the dataset.) However, computing
PC(r) for different values of r requires measuring the distance between every
pair of elements in S, that is, a O(N2) problem where N is the number of
elements in the dataset.
An alternative and more efficient approach is to estimate D by the
Correlation Fractal Dimension D2 in a range of scales [r1; r2].) Equation 2
gives D2 defined according to the “Box-Occupancy Counting” method, such
that r is the side of the cells in a (hyper) cubic grid which divides the address
space of the dataset, and is the count of elements (’occupancy’) in the i-th
cell.
Based on Equation 2, the log-log graph of the sum of squared occupancy
for distinct values of r is called Box-Counting plot. For a fractal dataset,
the resulting curve closely approaches a line, whose slope gives the Correlation
Fractal Dimension D2 of the dataset in the range [r1; r2].) Figure 5a shows the
Box-Counting plot of a Sierpinsky triangle composed of 6,561 points, generated
through 8 recursive iterations. Figure 5b presents the Box-Counting plot of the
MGCounty dataset, whose elements are the geographical coordinates of streets
and roads of the Montgomery County. In both examples, the curve is linear for
a significant range of scales.