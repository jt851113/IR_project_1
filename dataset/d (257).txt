Once results have been sampled and all local operators have been applied, they are enqueued onto a radio queue for delivery to the node’s parent. This queue contains both tuples from the local node as well as tuples that are being forwarded on behalf of other nodes in the network. When network contention and data rates are low, this queue can be drained faster than results arrive. However, because the number of messages produced during a single epoch can vary dramatically, depending on the number of queries running, the cardinality of joins, and the number of groups and aggregates, there are situations when the queue will over?ow. In these situations, the system must decide if it should try to retransmit this tuple, re-enqueue this tuple and try to send a different tuple, combine this tuple with some other tuple for the same query, or simply discard the tuple.
The ability to make runtime decisions about the value of an individual data item is central to ACQP systems, because the cost of acquiring and delivering data is high, and because of these situations where the rate of data items arriving at a node will exceed the maximum delivery rate. A simple conceptual approach for making such runtime decisions is as follows: whenever the system is ready to deliver a tuple, send the result that will most improve the “quality” of the answer that the user sees. Clearly, the proper metric for quality will depend on the application: for a raw signal, root-mean-square (RMS) error is a typical metric. For aggregation queries, minimizing the con?dence intervals of the values of group records could be the goal [38]. In other applications, users may be concerned with preserving frequencies, receiving statistical summaries (average, variance, or histograms), or maintaining more tenuous qualities such as signal “shape”.
Our goal is not to fully explore the spectrum of techniques available in this space. Instead, we have implemented several policies in TinyDB to illustrate that substantial quality improvements are possible given a particular workload and quality metric. Generalizing concepts of quality and implementing and exploring more sophisticated prioritization schemes remains an area of future work.
There is a large body of related work on approximation and compression schemes for streams in the database literature (e.g. [17, 9]), although these approaches typically focus on the problem of building histograms or summary structures over the streams rather than trying to preserve the (in order) signal as best as possible, which is the goal we tackle ?rst. Algorithms from signal processing, such as Fourier analysis and wavelets are likely applicable, although the extreme memory and processor limitations of our devices and the online nature of our problem (e.g. choosing which tuple in an over?owing queue to evict) make it non-obvious how to apply them.
We begin with a comparison of three simple prioritization schemes, naive, winavg, and delta for simple selection queries. In the naive scheme no tuple is considered more valuable than any other, so the queue is drained in a FIFO manner and tuples are dropped if they do
not ?t in the queue.
The winavg scheme works similarly, except that instead of dropping results when the queue ?lls, the two results at the head of the queue are averaged to make room for new results. Since the head of the queue is now an average of multiple records, we associate a count with it.
In the delta scheme, a tuple is assigned an initial score relative to its difference from the most recent (in time) value successfully transmitted from this node, and at each point in time, the tuple with the highest score is delivered. The tuple with the lowest score is evicted when the queue over?ows. Out of order delivery (in time) is allowed. This scheme relies on the intuition that the largest changes are probably interesting. It works as follows: when a tuple t with timestamp T is initially enqueued and scored, we mark it with the timestamp R of this most recently delivered tuple r. Since tuples can be delivered out of order, it is possible that a tuple with a timestamp between R and T could be delivered next (indicating that r was delivered out of order), in which case the score we computed for t as well as its R timestamp are now incorrect. Thus, in general, we must rescore some enqueued tuples after every delivery.
We compared these three approaches on a single mote running TinyDB. To measure their effect in a controlled setting, we set the sample rate to be a ?xed number K faster than the maximum delivery rate (such that 1 of every K tuples was delivered, on average) and compared their performance against several prede?ned sets of sensor readings (stored in the EEPROM of the device.) In this case, delta had a buffer of 5 tuples; we performed reordering of out of order tuples at the basestation. To illustrate the effect of winavg and delta, Figure 8 shows how delta and winavg approximate a high-periodicity trace of sensor readings generated by a shaking accelerometer (we omit naive due to space constraints.) Notice that delta is considerably closer in shape to the original signal in this case, as it is tends to emphasize extremes, whereas average tends to dampen them.
 We also measured RMS error for this signal as well as two others: a square wave-like signal from a light sensor being covered and uncovered, and a slow sinusoidal signal generated by moving a magnet around a magnetometer. The error for each of these signals and techniques is shown in Table 4. Although delta appears to match the shape of the acceleration signal better, its RMS value is about the same as average’s (due to the few peaks that delta incorrectly merges together.) Delta out performs either other approach for the fast changing step-functions in the light signal because it does not smooth edges as much as average.
We omit a discussion of prioritization policies for aggregation queries. TAG [31] discusses several snooping-based techniques unique to sensor networks that can be used to priortize aggregation queries. There is also signi?cant related work on using wavelets and histograms to approximate distributions of aggregate queries when there are many groups, for example [17, 9]. These techniques are applicable in sensor networks as well, although we expect that the number of groups will be small (e.g. at most tens or hundreds), so they may be less valuable.
Thus, we have illustrated some examples where prioritization of results can be used improve the overall quality of that data that are transmitted to the root when some results must be dropped or aggregated. Choosing the proper policies to apply in general, and understanding how various existing approximation and prioritization schemes map into ACQP is an important future direction.