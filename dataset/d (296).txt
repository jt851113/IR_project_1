Query processing takes place on a database front-end while signal-processing functions are executed on the sensor nodes involved in the query.  The query execution engine on the database front-end includes a mechanism for interacting with remote sensors. On each sensor a lightweight query execution engine is responsible for executing signal processing functions and sending data back to the front-end. In COUGAR, we assume that there are no modifications to the stored data during the execution of a long-running query. Strict two-phase locking on the database frontend ensures that this assumption is verified.  The initial version of COUGAR does not consider a long-running query as a persistent view; the system only computes the incremental results that could be used to maintain such a view. These incremental results are obtained by evaluating sensor ADT functions repeatedly and by combining the outputs they produce over time with stored data.  The execution of Sensor ADT functions is the central element of sensor queries execution. In the rest of the section, we show why the traditional execution of ADT functions (which is explained below) is inappropriate for sensor queries and we present the mechanisms we have implemented in COUGAR to evaluate sensor ADT functions. 
Problems with the Traditional ADT Functions Execution In most object-relational database systems, ADT functions are used to form expressions together with constants and variables. When an expression containing an ADT function is evaluated, a (local) function is called to obtain its return value. It is assumed that this return value is readily available on-demand. This assumption does not hold in a sensor database for the following reasons: 1. Scalar sensor ADT functions incur high latency due to their location or because they are asynchronous; 2. When evaluating long-running queries, sensor ADT functions return multiple outputs. To illustrate these problems, let us consider Query 1 in our example. One possible execution plan for Query 1 would be the following. For each temperature sensor in the relation R, the scalar function detectAlarmTemp(100) is applied.  
There is a serious flaw in this execution. First, the function detectAlarmTemp (100) is asynchronous, i.e. it returns its output after an arbitrary amount of time. While the system is requesting an abnormal temperature on the first sensor of the relation R, the other temperature sensors have not been yet been contacted. It may very well be that some temperature sensors could have detected temperatures greater than 100, while the system is blocked waiting for the output of one particular function.  Second, during the span of a long-running query, detectAlarmTemp (100) might return multiple outputs. The evaluation plan we presented scans relation R once and thus does not respect the semantics of long running queries we have introduced in Section 2. 
Virtual Relations To overcome the problems outlined in the previous paragraph, we introduced a relational operator to model the execution of sensor ADT functions. This relational operator is a variant of a join between the relation that contains the sensor ADT attribute and the sensor ADT function represented in a tabular form. We call the tabular representation of a function a virtual relation.  A virtual relation is a tabular representation of a method. A record in a virtual relation (called a virtual record) contains the input arguments and the output argument of the method it is associated with2. Such relations are called virtual because they are not actually materialized, as opposed to base relations, which are defined in the database schema.  If a method M takes m arguments, then the schema of its associated virtual relation has m+3 attributes, where the first attribute corresponds to the unique identifier of a device (i.e., the identifier of an actual device ADT object), attributes 2 to m+1 correspond to the input arguments of M, attribute m+2 corresponds to the output value of M and attribute m+3 is a time stamp corresponding to the point in time at which the output value is obtained. In our example Query 1, the virtual relation VRdetectAlarmTemp is defined for the Sensor ADT function detectAlarmTemp(). Since this function takes one input arguments, the virtual relation has four attributes: SensorId, Temp, Value, and TimeStamp, i.e., the identifier of the Sensor device that produces the data SensorId, the input threshold temperature Temp, the Value of the measured temperature and the associated TimeStamp. We observe the following: ‧ A virtual relation is append-only: New records are appended to a virtual relation when the associated signal processing function returns a result. Records in a virtual relation are never updated or deleted. ‧ A virtual relation is naturally partitioned across all devices represented by the same sensor ADT: A virtual relation is associated to a sensor ADT function, to each sensors of these type is associated a fragment of the virtual relation. The virtual relation is the union of all these fragments. The latter observation has an interesting consequence: a device database is internally represented as a distributed database. Virtual relations are partitioned across a set of devices. Base relations are stored on the database front-end. Distributed query                                                            2 We assume without loss of generality that a device function has exactly one return value; an extension to the general case is straightforward. 
processing techniques are not implemented in the initial version of COUGAR; their design and integration is the main goal of COUGAR V2 that we are currently implementing. 
Query Execution Plan Virtual relations appear in the query execution plan at the same level as base relations. Base relations are accessed through (indexed) scans. Each virtual relation fragment is accessed on sensors using a virtual scan. A virtual scan incorporates in the query execution plan the propagation mechanism necessary to support long-running queries. Our notion of virtual scan over a virtual relation fragment is similar to the fetch_wait cursor over an active relation in the Alert database system [18]. A fetch_wait cursor provides a blocking read behavior. This fetch_wait cursor returns new records as they are inserted in the active relation and blocks when all records have been returned. A classical cursor would just terminate when all records currently in the relation have been returned.  The join between a base relation and a virtual relation is basically a nested loop with a pipelined access to the virtual scans that encapsulate the execution of the sensor ADT function.  (Note that we make the simplifying assumption that arguments to the sensor ADT functions are constants.) Indeed, the sensor ADT function is applied with identical parameters on all sensors involved in the query. The algorithm is presented below. 
In: Base relation R, sensor ADT function f 
Out: join between relation R and virtual relation associated to f 
Initialize virtual scans for the virtual relation fragments associated to f on all sensors involved in the query 
FOREVER DO 
   Get next output from the sensor virtual scan 
   Find a matching sensor id in the base relation R 
   If match is found then return record 
ENDLOOP 
The incremental results produced by a virtual join are directly transmitted to the client, or they are pipelined to the root of the execution plan (as the outer child in a nested loop join for instance3). Consequently, queries with relational aggregates or ‘ORDER BY’ clauses do not return an incremental result. Indeed, such queries require an operator to accumulate all the results produced by its children. With such operators no incremental results are produced before the query is stopped. 
                                                           3 Note that queries with sensor ADT functions applied on more than one collection of sensors require that the join between two virtual joins is a double-pipelined join. 