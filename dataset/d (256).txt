Query execution consists of a simple sequence of operations at each node during every epoch: ?rst, nodes sleep for most of an epoch; then they wake, sample sensors and apply operators to data generated locally
and received from neighbors, and then deliver results to their parent. We (brie?y) describe ACQP-relevant issues in each of these phases.
Nodes sleep for as much of each epoch as possible to minimize power consumption. They wake up only to sample sensors and relay and deliver results. Because nodes are time synchronized, they all sleep and wake up at the same time, ensuring that results will not be lost as a result of a parent sleeping when a child tries to propagate a message. The amount of time, tawake that a sensor node must be awake to successfully accomplish the latter three steps above is largely dependent on the number of other nodes transmitting in the same radio cell, since only a small number of messages per second can be transmitted over the single shared radio channel.
TinyDB uses a simple algorithm to scale tawake based on the neighborhood size, the details of which we omit. Note, however, that there are situations in which a node will be forced to drop or combine results as a result of the either tawake or the sample interval being too short to perform all needed computation and communication. We discuss policies for choosing how to aggregate data and which results to drop in the next subsection.
Once a node is awake, it begins sampling and ?ltering results according to the plan provided by the optimizer. Samples are taken at the appropriate (current) sample rate for the query, based on lifetime computations and information about radio contention and power consumption (see Section 6.3 for more information on how TinyDB adapts sampling in response to variations during execution.) Filters are applied and results are routed to join and aggregation operators further up the query plan.
For aggregation queries across nodes, we adopt the approach of TAG [31], although TAG does not support temporal aggregates but only aggregates of values from different nodes produced in the same epoch.
The basic approach used in both TAG and TinyDB is to compute a partial state record at each intermediate node in the routing topology. This record represents the partially evaluated aggregation of local sensor values with sensor values received from child nodes as they ?ow up the routing tree. The bene?t of doing this is that a great deal less data is transmitted than when all sensorsâ€™ values are sent to the root of the network to be aggregated together.
Finally, we note that in event-based queries, the ON EVENT clause must be handled specially. When an event ?res on a node, that node disseminates the query, specifying itself as the query root. This node collects query results, and delivers them to the basestation or a local materialization point.
