In the previous tracking experiment, it was assumed that the set of events were all caused by the same object and could be processed by a centralized algorithm. In a real application, there will not be a priori knowledge of how many objects there are or whether the events are the result of other phenomena. What is needed is an algorithm for making sense of the events in a distributed and sequential manner. It is assumed no centralized processing node is available, but that there is some distant reporting node where the final results need to be reported to.
By initiating a sequence for estimating after an event, the node is starting a hypothesis that the event was caused by an object moving in the sensor field. This hypothesis is sent to surrounding nodes where it is stored. If an event occurs at these nodes that is associated with a stored hypothesis, this hypothesis can be updated and broadcast again. Thus, the hypotheses and their estimates are propagated through the nodes in the network. They are stored at the nodes, and are updated as events occur. Old hypotheses expire, and redundant hypotheses are pruned.
For detection purposes, a confirmed target is reported after a hypothesis has reached some detection criteria (a suitable number of transitions c will be used here). For longer-term tracking applications of a confirmed object, the track can be reported at regular time intervals, but not necessarily at every transition. The inherent power saving in such distributed algorithms is obvious - many local broadcasts but relatively few global broadcasts. While distributed tracking/classification is possible using this idea, for brevity distributed detection (or track initiation) will be examined for the rest of this paper.