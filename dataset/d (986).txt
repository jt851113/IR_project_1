We implemented our greedy aggregation in the ns-2 simulator [3]. Our goals in conducting this evaluation study were four-fold: First, verify the viability of the greedy aggregation as an alternative instantiation of directed diffusion.
Second, understand the impact of network dynamics (e.g., node failures) on the greedy aggregation and the opportunistic aggregation. Third, explore the influence of the source placement scheme on the performance of both approaches. Finally, study the sensitivity of the greedy aggregation to the parameter choices. We select three metrics to analyze the performance of the greedy aggregation and to compare it to the opportunistic
aggregation: average dissipated energy, average delay, and distinct-event delivery ratio. These metrics were used in earlier work to compare diffusion with other idealized schemes [12]. Average dissipated energy measures the ratio of total dissipated energy per node in the network to the number of distinct events received by sinks. This metric computes the average work done by a node in delivering useful information to the sinks. The metric also indicates the overall lifetime of sensor nodes. Average delay measures the average one-way latency observed between transmitting an event and receiving it at each sink. This metric defines the temporal accuracy of the phenomena detection delivered by the sensor network. The distinct-event delivery ratio is the ratio of the number of distinct events received to the number originally sent. This metric indicates the robustness to network dynamics. We study
these metrics as a function of sensor network density.
To completely specify our experimental methodology, we need to describe the sensor network generation procedure (e.g., our choice of ratio parameters, our workload). In order to study the performance of the greedy aggregation
as a function of network density, we generate a variety of sensor fields in a 200m by 200m square. In most of our experiments, we study seven different sensor fields, ranging from 50 to 350 nodes in increments of 50 nodes. Each
sensor field generated by randomly placing the nodes in the square. Each node has a radio range of 40m. Thus,the radio density (expressed in terms of how many other nodes each node can hear on average) ranges from 6 to 43 neighbors. For each network size, our results are averaged over ten different generated fields.
The ns-2 simulator implements a 1.6 Mbps 802.11 MAC layer. Our simulations use a modified 802.11 MAC
layer. To more closely mimic realistic sensor network radios [13], we altered the ns-2 radio energy model such that the idle time power dissipation was about 35mW, or nearly 10% of its receive power dissipation (395mW), and about 5% of its transmit power dissipation (660mW).
Finally, in most of our simulations, we use a fixed workload which consists of five sources and one sink. All sources are randomly selected from nodes in a 80m by 80m square at the bottom left corner of the sensor field.The sink is randomly selected from nodes in a 36m by 36m square at the top right corner of the field. This source placement scheme differs from the event-radius model [14] for the low-level data aggregation because sources may not be triggered by the same phenomena and may not be within one hop from one another. Similar to the random
source placement model [14], our source placement scheme is intended for the high-level data aggregation except that all sources in our placement scheme are placed in a subregion of the sensor field far from the sink. Our greedy aggregation targets high-level data (e.g., abstract event represenation) because we expect that low-level data (e.g.,
seimic signals) will be locally processed. Therefore, only the random source placement scheme and our source placement scheme are used in this evaluation.
Each source generates two events per second. Thus, the aggregation delay is set to 0.5 seconds. The rate for exploratory events was chosen to be one event in 50 seconds. Events were modeled as 64 byte packets and other messages were 36 byte packets. The size of aggregates depends on the aggregation function and the number of data items in the aggregates (Section 5.4). For the perfect aggregation, the aggregate size is 64 bytes. Interests were periodically generated every 5 seconds and the gradient timeout was 15 seconds. We chose the window for negative reinforcement to be 2 seconds and the timer  for positive reinforcement to be 1 second.